---
noteId: 1743196637599
---

# Планировщик Go (Scheduler)

**Планировщик Go** — это компонент рантайма, который распределяет горутины по потокам операционной системы (OS Threads). Его задача — эффективно использовать ресурсы CPU, минимизируя накладные расходы на переключение контекста.

### Состояния треда & горутин в ОС
Перед тем как разбирать Go, вспомним, в каких состояниях бывает поток (Thread) в операционной системе:
1.  **Executing**: Тред выполняется прямо сейчас на одном из ядер CPU.
2.  **Runnable**: Тред готов к выполнению и стоит в очереди планировщика ОС.
3.  **Waiting**: Тред заблокирован (ждет ввода-вывода, мьютекса или системного вызова).
У горутин состояние примерно аналогичное.

![[Pasted image 20251029093611.png]]
![[Pasted image 20251029094729.png]]

---

## 1. Зачем Go свой планировщик?

У операционной системы (ОС) уже есть свой планировщик, который управляет потоками (Threads). Почему Go не использует их напрямую?

### Проблемы потоков ОС
1.  **Дорогое переключение контекста**:
    Когда ОС переключает треды, она должна сохранить регистры, флаги, обнулить кеш L1/L2. Это занимает **1-2 мкс**. Для высоконагруженных систем это слишком долго.
    ![[Pasted image 20251029093636.png]]

2.  **Потребление памяти**:
    Каждый тред имеет фиксированный стек (обычно **2-8 МБ**). Создать 100,000 тредов невозможно — закончится RAM.

### Решение Go (User-space scheduling)
Go использует модель **M:N**, где **N** горутин выполняются на **M** потоках ОС.
-  **Горутина** весит от **2 КБ**.
-  Переключение контекста стоит **~200 нс** (в 10 раз быстрее), так как происходит в user-space и сохраняет минимум данных (PC, SP, DX).

![[Pasted image 20251029094729.png]]

---

## 2. Эволюция модели (M-P-G)

Чтобы понять, как работает планировщик, рассмотрим его эволюцию.

### Этап 1: Просто Пул Тредов (Thread Pool)
Сначала мы могли бы просто создать пул тредов. Когда горутина готова, мы даем ей свободный тред. 
![[Pasted image 20251029095221.png]]

**Проблема**: Если все треды заняты, новым горутинам приходится ждать в глобальной очереди (**GRQ** — Global Run Queue).
![[Pasted image 20251029095226.png]]

### Этап 2: Проблема Глобальной Очереди
Если все процессоры (P) ломятся в одну общую GRQ за работой, нам нужен **Мьютекс** (Lock), чтобы они не подрались за одну задачу.
![[Pasted image 20251029095304.png]]
![[Pasted image 20251029095452.png]]

**Проблема**: Мьютекс на каждый чих убивает производительность (Contention). Чем больше ядер, тем хуже.

### Этап 3: Введение P и Локальных Очередей (LRQ)
Чтобы убрать блокировки, в Go ввели сущность **P (Processor)**. У каждого P есть своя **Локальная Очередь (LRQ)**.

![[Pasted image 20251029100024.png]]

Теперь модель выглядит так (**M-P-G**):
1.  **G (Goroutine)** — Горутина (код, стек).
2.  **M (Machine)** — Поток ОС (исполнитель).
3.  **P (Processor)** — Логический контекст (ресурс). 
    -   Хранит **LRQ** (до 256 горутин).
    -   Количество P = `GOMAXPROCS` (= `runtime.NumCPU()`).

---

## 3. Цикл планирования `schedule()`

Когда поток `M` ищет следующую задачу для выполнения, он следует строгому алгоритму. Главная цель — найти горутину как можно быстрее и с минимальными блокировками.

### Источники горутин (Приоритеты)

1.  **Глобальная очередь (Раз в 61 такт)**:
    Каждый 61-й цикл планировщик игнорирует локальные приоритеты и идет в **GRQ**. Это нужно, чтобы горутины в общей очереди не "голодали", если локальные очереди всегда забиты.
2.  **Локальная очередь (LRQ)**:
    Берем из основной очереди процессора (FIFO).
3.  **Глобальная очередь (GRQ)**:
    Если в LRQ пусто, идем в общую очередь.
4.  **Network Poller**:
    Проверяем, не проснулись ли сетевые горутины.
5.  **Work Stealing**:
    Если совсем ничего нет, пытаемся украсть половину задач у другого случайного `P`.

---

## 4. Блокирующие операции (Syscalls)

Что если горутина делает тяжелый системный вызов (чтение файла), который блокирует тред?

### Синхронный (Blocking) Syscall — Handoff
Если вызов действительно блокирует тред (например, cgo или долгая файловая операция):
1.  Планировщик видит, что `M` заблокировался.
2.  Он **отцепляет (handoff)** `P` от этого `M`.
3.  `P` ищет новый (или спящий) `M`, чтобы продолжить выполнять *другие* горутины из очереди.
4.  Старый `M` "спит" вместе с заблокированной G, пока вызов не завершится.

![[Pasted image 20251029102100.png]]
*(до)*
![[Pasted image 20251029102137.png]]
*(после handoff — P ушел к другому M)*

**Что происходит после завершения Syscall?**
Когда системный вызов завершается, горутина G пытается вернуться в строй:
1.  Она ищет свой "родной" `P`, на котором работала до блокировки.
2.  Если родной `P` занят, она ищет любой другой свободный `P` в пуле.
3.  Если свободных `P` нет, горутина кладется в **Глобальную очередь (GRQ)**, а её тред `M` уходит в спячку (пул тредов).

### Асинхронный (Non-blocking) I/O — Network Poller
Для сетевых вызовов Go использует **Network Poller** (поверх `epoll` / `kqueue`).
1.  Горутина делает сетевой запрос.
2.  Вместо блокировки треда, G перемещается в список ожидания Network Poller'а.
3.  `M` продолжает выполнять следующую горутину из очереди.
4.  Когда сеть ответит, Netpoller вернет G обратно в очередь Ready.

![[Pasted image 20251029102551.png]]
*(регистрация в pollere)*
![[Pasted image 20251029102615.png]]
*(M свободен для работы)*

---

## 5. Sysmon (System Monitor)

**Sysmon** — это фоновый поток (не горутина!), который запускается рантаймом на отдельном треде ОС. Он не зависит от `P` и выполняет функции "надсмотрщика":

1.  **Handoff при зависании**: Если Sysmon видит, что `M` находится в системном вызове дольше **10 мс**, он принудительно отцепляет `P` от него (handoff), чтобы тот не простаивал.
2.  **Проверка Netpoller**: Если планировщик давно не проверял сеть (>10 мс), Sysmon вытягивает готовые горутины из Netpoller и кладет их в GRQ.
3.  **Вытеснение (Preemption)**: Устанавливает флаги прерывания для "жадных" горутин, которые работают слишком долго.

![[Pasted image 20251029102222.png]]

---

## 6. Вытеснение (Preemption)

Как защититься от "жадной" горутины, которая крутится в `for {}` и не отдает процессор?

![[Pasted image 20251029103143.png]]

### Старый подход (Кооперативный)
До Go 1.14 использовалось вставки проверок (`stackguard`) в места вызова функций (прологи функций).
1.  Sysmon ставит флаг `stackguard = stackPreempt`.
2.  При вызове любой функции горутина проверяет этот флаг.
3.  Если флаг стоит — она понимает, что пора "сдаваться", сохраняет состояние и уходит в очередь.

**Проблема**: Если в цикле (`for {}`) нет вызовов функций, горутина могла повесить поток навсегда.

![[Pasted image 20251029103344.png]]
### Новый подход (Асинхронный, Go 1.14+) — Signals
Теперь Sysmon действует жестче:
1.  Если G работает >10 мс, Sysmon посылает сигналу потоку (`SIGURG`).
2.  Обработчик сигнала ОС прерывает выполнение в **любой** точке (даже если нет функций).
3.  Состояние G сохраняется, и она принудительно вытесняется.

---

## 7. Итоговая схема жизни горутины

![[Pasted image 20251029103541.png]]

1.  **Creation**: `go func()` -> G создается.
2.  **Queue**: Попадает в LRQ или GRQ.
3.  **Execute**: Исполняется на M.
4.  **Wait**:
    -   Сеть -> Netpoller.
    -   Syscall -> Handoff (M спит).
    -   Chan/Mutex -> Очередь ожидания (`sudog`).
5.  **Exit**: Освобождает стек.

---

